{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------- Important library used in our code -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------- Utility Function that are used in our code -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that load the data set into our program\n",
    "def loadData(data_set = None):\n",
    "\n",
    "    if (data_set == None):\n",
    "        return None\n",
    "    else:\n",
    "        data = []\n",
    "        fptr = open(data_set, \"r\")\n",
    "        lines = fptr.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split()\n",
    "            for i in range(len(line)):\n",
    "                line[i] = float(line[i])\n",
    "            # print(line)\n",
    "            data.append(line)\n",
    "        \n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that make the new data set based on statistical value\n",
    "def makeNewDataSet(data_set=None):\n",
    "\n",
    "    new_data_set = []\n",
    "\n",
    "    for i in range(0, len(data_set), 32):\n",
    "        \n",
    "        temp = []\n",
    "        x = data_set[i: i + 32, 0]\n",
    "        y = data_set[i: i + 32, 1]\n",
    "        z = data_set[i: i + 32, 2]\n",
    "        op = data_set[i][3]\n",
    "        # y = data_set[i][-1]\n",
    "\n",
    "        # adding mean to data set\n",
    "        temp.append(np.mean(x))\n",
    "        temp.append(np.mean(y))\n",
    "        temp.append(np.mean(z))\n",
    "\n",
    "        # adding median to the data set\n",
    "        temp.append(np.median(x))\n",
    "        temp.append(np.median(y))\n",
    "        temp.append(np.median(z))\n",
    "\n",
    "        # adding mode to the data set\n",
    "        temp.append(stats.mode(x, keepdims=True)[0][0])\n",
    "        temp.append(stats.mode(y, keepdims=True)[0][0])\n",
    "        temp.append(stats.mode(z, keepdims=True)[0][0])\n",
    "\n",
    "        # adding the standard deviation to the data set\n",
    "        temp.append(np.std(x))\n",
    "        temp.append(np.std(y))\n",
    "        temp.append(np.std(z))\n",
    "\n",
    "        # adding the quantile @25 in the data set\n",
    "        iq_1 = np.quantile(x, .25)\n",
    "        iq_2 = np.quantile(y, .25)\n",
    "        iq_3 = np.quantile(z, .25)\n",
    "        temp.append(iq_1)\n",
    "        temp.append(iq_2)\n",
    "        temp.append(iq_3)\n",
    "\n",
    "        # adding the quantile @50 in the data set\n",
    "        temp.append(np.quantile(x, .5))\n",
    "        temp.append(np.quantile(y, .5))\n",
    "        temp.append(np.quantile(z, .5))\n",
    "\n",
    "        # adding the quantile @75 in the data set\n",
    "        iq_1_ = np.quantile(x, .75)\n",
    "        iq_2_ = np.quantile(y, .75)\n",
    "        iq_3_ = np.quantile(z, .75)\n",
    "        temp.append(iq_1_)\n",
    "        temp.append(iq_2_)\n",
    "        temp.append(iq_3_)\n",
    "\n",
    "        # adding inter quantile in the data set\n",
    "        temp.append(iq_1_ - iq_1)\n",
    "        temp.append(iq_2_ - iq_2)\n",
    "        temp.append(iq_3_ - iq_3)\n",
    "\n",
    "        # adding the output \n",
    "        temp.append(op)\n",
    "\n",
    "        new_data_set.append(temp)\n",
    "        # print(temp, op)\n",
    "    \n",
    "    return np.array(new_data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new data set based on sliding window\n",
    "def makeNewDataSet2(data_set=None):\n",
    "\n",
    "    new_data_set = []\n",
    "\n",
    "    for i in range(0, len(data_set), 10):\n",
    "        \n",
    "        temp = []\n",
    "        x = data_set[i: i + 32, 0]\n",
    "        y = data_set[i: i + 32, 1]\n",
    "        z = data_set[i: i + 32, 2]\n",
    "        op = data_set[i: i + 32, 3]\n",
    "\n",
    "        find_most_common = lambda arr: max(Counter(arr).items(), key=lambda x: x[1])[0]\n",
    "        op = find_most_common(op)\n",
    "        # y = data_set[i][-1]\n",
    "\n",
    "        # adding mean to data set\n",
    "        temp.append(np.mean(x))\n",
    "        temp.append(np.mean(y))\n",
    "        temp.append(np.mean(z))\n",
    "\n",
    "        # adding median to the data set\n",
    "        temp.append(np.median(x))\n",
    "        temp.append(np.median(y))\n",
    "        temp.append(np.median(z))\n",
    "\n",
    "        # adding mode to the data set\n",
    "        temp.append(stats.mode(x, keepdims=True)[0][0])\n",
    "        temp.append(stats.mode(y, keepdims=True)[0][0])\n",
    "        temp.append(stats.mode(z, keepdims=True)[0][0])\n",
    "\n",
    "        # adding the standard deviation to the data set\n",
    "        temp.append(np.std(x))\n",
    "        temp.append(np.std(y))\n",
    "        temp.append(np.std(z))\n",
    "\n",
    "        # adding the quantile @25 in the data set\n",
    "        iq_1 = np.quantile(x, .25)\n",
    "        iq_2 = np.quantile(y, .25)\n",
    "        iq_3 = np.quantile(z, .25)\n",
    "        temp.append(iq_1)\n",
    "        temp.append(iq_2)\n",
    "        temp.append(iq_3)\n",
    "\n",
    "        # adding the quantile @50 in the data set\n",
    "        temp.append(np.quantile(x, .5))\n",
    "        temp.append(np.quantile(y, .5))\n",
    "        temp.append(np.quantile(z, .5))\n",
    "\n",
    "        # adding the quantile @75 in the data set\n",
    "        iq_1_ = np.quantile(x, .75)\n",
    "        iq_2_ = np.quantile(y, .75)\n",
    "        iq_3_ = np.quantile(z, .75)\n",
    "        temp.append(iq_1_)\n",
    "        temp.append(iq_2_)\n",
    "        temp.append(iq_3_)\n",
    "\n",
    "        # adding inter quantile in the data set\n",
    "        temp.append(iq_1_ - iq_1)\n",
    "        temp.append(iq_2_ - iq_2)\n",
    "        temp.append(iq_3_ - iq_3)\n",
    "\n",
    "        # adding the output \n",
    "        temp.append(op)\n",
    "\n",
    "        new_data_set.append(temp)\n",
    "        # print(temp, op)\n",
    "    \n",
    "    return np.array(new_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding number of left, right turn in the data\n",
    "def countTurns(data):\n",
    "    count_l = 0\n",
    "    count_r = 0\n",
    "    no_turn = 0\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "\n",
    "        if data[i][-1] == -1:\n",
    "            count_l += 1\n",
    "        \n",
    "        elif data[i][-1] == 1:\n",
    "            count_r += 1\n",
    "        \n",
    "        else:\n",
    "            no_turn += 1\n",
    "    \n",
    "    return {count_l, count_r, no_turn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that run the model at that size\n",
    "def runModelAtSize(split_ratio, model_name, X, y):\n",
    "    \n",
    "    output = [round(split_ratio, 1), model_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=round(split_ratio, 1), random_state=42)\n",
    "\n",
    "    if model_name == \"Descison tree\":\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Gaussian NB\":\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"SVM\":\n",
    "        model = SVC()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Gradient Boosting\":\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"MLP\":\n",
    "        model = MLPClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finction that run all the models at differnt size\n",
    "def runAllModels(data_set, file_name):\n",
    "    X = data_set[:, :-1]\n",
    "    y = data_set[:, -1]\n",
    "\n",
    "    # smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    # X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    outputs = [[\"Split ratio\", \"Model\", \"Train Accuracy\", \"Test Accuracy\"]]\n",
    "    \n",
    "    # Run model 1: Descision tree\n",
    "    split_ratio = 0.2\n",
    "    for i in range(5):\n",
    "        outputs.append(runModelAtSize(split_ratio, \"Descison tree\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"Random Forest\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"KNN\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"AdaBoost\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"Gaussian NB\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"SVM\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"Gradient Boosting\", X, y))\n",
    "        outputs.append(runModelAtSize(split_ratio, \"MLP\", X, y))\n",
    "\n",
    "\n",
    "        outputs.append([\"-------------\"] * len(outputs[0]))\n",
    "        split_ratio += 0.1\n",
    "\n",
    "    out = tabulate(outputs, headers=\"firstrow\")\n",
    "    fptr = open(file_name, \"w\")\n",
    "    fptr.write(out)\n",
    "    fptr.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that run the model at that size\n",
    "def runModelAtSizeNew(split_ratio, model_name, X, y):\n",
    "    \n",
    "    output = [model_name]\n",
    "    length = len(X)\n",
    "    x_len = int(0.3 * length)\n",
    "    y_len = int(length) - x_len\n",
    "    X_train = X[:x_len] \n",
    "    X_test = X[x_len:] \n",
    "    y_train = y[:x_len] \n",
    "    y_test = y[x_len:]\n",
    "\n",
    "    if model_name == \"Descison tree\":\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Gaussian NB\":\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"SVM\":\n",
    "        model = SVC()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"Gradient Boosting\":\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    elif model_name == \"MLP\":\n",
    "        model = MLPClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Train Accuracy\n",
    "        y_pred = model.predict(X_train)\n",
    "        output.append(accuracy_score(y_pred, y_train)*100)\n",
    "\n",
    "        # Test Accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelswithFreq(data_set):\n",
    "    \n",
    "    X = data_set[:, :-1]\n",
    "    y = data_set[:, -1]\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    # Run model 1: Descision tree\n",
    "    split_ratio = 0.3\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Descison tree\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Random Forest\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"KNN\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"AdaBoost\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gaussian NB\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"SVM\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gradient Boosting\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"MLP\", X, y))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelswithoutFreq(data_set):\n",
    "    \n",
    "    X = data_set[:, -4:-1]\n",
    "    y = data_set[:, -1]\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    # Run model 1: Descision tree\n",
    "    split_ratio = 0.3\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Descison tree\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Random Forest\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"KNN\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"AdaBoost\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gaussian NB\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"SVM\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gradient Boosting\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"MLP\", X, y))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelsOld(data_set):\n",
    "    \n",
    "    X = data_set[:, :-4]\n",
    "    y = data_set[:, -1]\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    # Run model 1: Descision tree\n",
    "    split_ratio = 0.3\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Descison tree\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Random Forest\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"KNN\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"AdaBoost\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gaussian NB\", X, y))\n",
    "    # outputs.append(runModelAtSizeNew(split_ratio, \"SVM\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"Gradient Boosting\", X, y))\n",
    "    outputs.append(runModelAtSizeNew(split_ratio, \"MLP\", X, y))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that find Individual Accuracy for new left, right, no turn on split ration 0.2\n",
    "def individualAccuracyNew(data_set, file_name):\n",
    "    \n",
    "    X = data_set[:, :-1]\n",
    "    y = data_set[:, -1]\n",
    "\n",
    "    X_left = []\n",
    "    X_right = []\n",
    "    X_no = []\n",
    "\n",
    "    y_left = []\n",
    "    y_right = []\n",
    "    y_no = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "         \n",
    "        if (y[i] == 0):\n",
    "            X_no.append(X[i])\n",
    "            y_no.append(0)\n",
    "        \n",
    "        elif (y[i] == 1):\n",
    "            X_right.append(X[i])\n",
    "            y_right.append(1)\n",
    "        \n",
    "        else:\n",
    "            X_left.append(X[i])\n",
    "            y_left.append(-1)\n",
    "\n",
    "    X_left_train, X_left_test, y_left_train, y_left_test =  train_test_split(X_left, y_left, test_size=0.2, random_state=42)\n",
    "    X_right_train, X_right_test, y_right_train, y_right_test =  train_test_split(X_right, y_right, test_size=0.2, random_state=42)\n",
    "    X_no_train, X_no_test, y_no_train, y_no_test =  train_test_split(X_no, y_no, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    outputs = [[\"Model\", \"Left Train Accuracy\", \"Right Train Accuracy\", \"No Turn Accuracy\", \"Left Test Accuracy\", \"Right Test Accuracy\", \"No Test Accuracy\"]]\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"Descison tree\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "   \n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"Random Forest\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"KNN\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    model = AdaBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"AdaBoost\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"Gaussian NB\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"SVM\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"Gradient Boosting\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "\n",
    "    model = MLPClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    output = [\"MLP\"]\n",
    "    \n",
    "    y_pred = model.predict(X_left_train)\n",
    "    output.append(accuracy_score(y_pred, y_left_train)*100)\n",
    "    y_pred = model.predict(X_right_train)\n",
    "    output.append(accuracy_score(y_pred, y_right_train)*100)\n",
    "    y_pred = model.predict(X_no_train)\n",
    "    output.append(accuracy_score(y_pred, y_no_train)*100)\n",
    "\n",
    "    y_pred = model.predict(X_left_test)\n",
    "    output.append(accuracy_score(y_pred, y_left_test)*100)\n",
    "    y_pred = model.predict(X_right_test)\n",
    "    output.append(accuracy_score(y_pred, y_right_test)*100)\n",
    "    y_pred = model.predict(X_no_test)\n",
    "    output.append(accuracy_score(y_pred, y_no_test)*100)\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "    fptr = open(file_name, \"w\")\n",
    "    op = tabulate(outputs, headers=\"firstrow\")\n",
    "\n",
    "    fptr.write(op)\n",
    "\n",
    "    fptr.write(\"\\nFor training data\")\n",
    "    fptr.write(f\"\\nleft: {len(X_left_train)} right: {len(X_right_train)} no_turn: {len(X_no_train)}\")\n",
    "    fptr.write(\"\\nFor testing data\")\n",
    "    fptr.write(f\"\\nleft: {len(X_left_test)} right: {len(X_right_test)} no_turn: {len(X_no_test)}\")\n",
    "\n",
    "    fptr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that train on one data set and test on other data set\n",
    "def runAllDataSet(file_name, test_data_set, *train_data_sets):\n",
    "\n",
    "    training_data_set = train_data_sets[0]\n",
    "\n",
    "    for i in range(1, len(train_data_sets)):\n",
    "        training_data_set = np.concatenate((training_data_set, train_data_sets[i]))\n",
    "    \n",
    "    # training_data_set = np.array(training_data_set)\n",
    "    \n",
    "    # fptr = open(file_name, \"w\")\n",
    "\n",
    "    X_train = training_data_set[:, :-1]\n",
    "    y_train = training_data_set[:, -1]\n",
    "\n",
    "    X_test = test_data_set[:, :-1]\n",
    "    y_test = test_data_set[:, -1]\n",
    "\n",
    "    # smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    # X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # X_test, y_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "\n",
    "    outputs = [[\"Model_name\" , \"training\", \"testing\"]]\n",
    "\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"Descison tree\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"Random Forest\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"KNN\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = AdaBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"AdaBoost\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"Gaussian NB\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"SVM\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"Gradient Boosting\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    model = MLPClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    output = [\"MLP\"]\n",
    "    y_pred = model.predict(X_train)\n",
    "    output.append(accuracy_score(y_pred, y_train)*100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    output.append(accuracy_score(y_pred, y_test)*100)\n",
    "    outputs.append(output)\n",
    "\n",
    "    # tab = tabulate(outputs, headers=\"firstrow\")\n",
    "\n",
    "    # fptr.write(tab)\n",
    "\n",
    "    # fptr.close()\n",
    "\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------- variables that are used in our code -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set_1 = loadData(\"3_19/visual_freq_rat.txt\")\n",
    "data_set_2 = loadData(\"4_57/visual_freq_rat.txt\")\n",
    "data_set_3 = loadData(\"5_11/visual_freq_rat.txt\")\n",
    "data_set_4 = loadData(\"Australia/visual_freq_rat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.03125   , -9.03125   , 62.1875    , 10.        , -9.        ,\n",
       "       62.        , 10.        , -9.        , 62.        ,  0.39404751,\n",
       "        0.17399264,  0.39031237, 10.        , -9.        , 62.        ,\n",
       "       10.        , -9.        , 62.        , 10.        , -9.        ,\n",
       "       62.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_1[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllModels(data_set_1, \"Output/driver_1_freq_only.txt\")\n",
    "runAllModels(data_set_2, \"Output/driver_2_freq_only.txt\")\n",
    "runAllModels(data_set_3, \"Output/driver_3_freq_only.txt\")\n",
    "runAllModels(data_set_4, \"Output/driver_4_freq_only.txt\")\n",
    "# runAllModels(new_data_set_4, \"Output/driver_4_freq.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualAccuracyNew(data_set_1, \"Output/int_ind_1.txt\")\n",
    "individualAccuracyNew(data_set_2, \"Output/int_ind_2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_set_1 = makeNewDataSet2(loadData('3_19/visual_annotion_3_19.txt'))\n",
    "new_data_set_2 = makeNewDataSet2(loadData(\"4_57/visual_annotation_4_57.txt\"))\n",
    "new_data_set_3 = makeNewDataSet2(loadData(\"5_11/visual_annotion_5_11.txt\"))\n",
    "new_data_set_4 = makeNewDataSet2(loadData(\"Australia/visual_annotation_aus.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "op_driver_1_old = runModelsOld(data_set_1)\n",
    "op_driver_2_old = runModelsOld(data_set_2)\n",
    "op_driver_3_old = runModelsOld(data_set_3)\n",
    "op_driver_4_old = runModelsOld(data_set_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Descison tree', 100.0, 25.0],\n",
       " ['Random Forest', 100.0, 16.666666666666664],\n",
       " ['KNN', 60.0, 18.333333333333332],\n",
       " ['AdaBoost', 36.0, 23.333333333333332],\n",
       " ['Gaussian NB', 72.0, 18.333333333333332],\n",
       " ['Gradient Boosting', 100.0, 18.333333333333332],\n",
       " ['MLP', 92.0, 11.666666666666666]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_driver_1_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable that stores the data\n",
    "data_set_1 = loadData(\"5_11/visual_annotion_5_11.txt\")\n",
    "new_data_set_1 = makeNewDataSet2(data_set = data_set_1)\n",
    "new_data_set_2 = makeNewDataSet2(loadData('3_19/visual_annotion_3_19.txt'))\n",
    "new_data_set_3 = makeNewDataSet2(loadData(\"4_57/visual_annotation_4_57.txt\"))\n",
    "new_data_set_4 = makeNewDataSet2(loadData(\"Australia/visual_annotation_aus.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllModels(new_data_set_1, \"Output/driver_1_freq.txt\")\n",
    "runAllModels(new_data_set_2, \"Output/driver_2_freq.txt\")\n",
    "runAllModels(new_data_set_3, \"Output/driver_3_freq.txt\")\n",
    "runAllModels(new_data_set_4, \"Output/driver_4_freq.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualAccuracyNew(new_data_set_1, \"Output/indiv_1.txt\")\n",
    "individualAccuracyNew(new_data_set_2, \"Output/indiv_2.txt\")\n",
    "individualAccuracyNew(new_data_set_3, \"Output/indiv_3.txt\")\n",
    "individualAccuracyNew(new_data_set_4, \"Output/indiv_4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{481, 315, 1438}\n",
      "2698\n"
     ]
    }
   ],
   "source": [
    "# let check the number of turns in the data set and total number of rows\n",
    "print(countTurns(new_data_set_1))\n",
    "print(len(new_data_set_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllDataSet(\"Output/test_aus_smote.txt\", new_data_set_4, new_data_set_1, new_data_set_2, new_data_set_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllDataSet(\"Output/test_1_smote.txt\", new_data_set_1, new_data_set_4, new_data_set_2, new_data_set_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllDataSet(\"Output/test_2_smote.txt\", new_data_set_2, new_data_set_4, new_data_set_1, new_data_set_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllDataSet(\"Output/test_3_smote.txt\", new_data_set_3, new_data_set_4, new_data_set_2, new_data_set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set_1 = loadData(\"3_19/visual_freq_rat.txt\")\n",
    "# data_set_2 = loadData(\"4_57/visual_freq_rat.txt\")\n",
    "# data_set_3 = loadData(\"5_11/visual_freq_rat.txt\")\n",
    "# data_set_4 = loadData(\"Australia/visual_freq_rat.txt\")\n",
    "\n",
    "\n",
    "data_set_1 = loadData(\"3_19/visual_freq_rat.txt\")\n",
    "data_set_2 = loadData(\"4_57/visual_freq_rat.txt\")\n",
    "data_set_3 = loadData(\"5_11/visual_freq_rat.txt\")\n",
    "data_set_4 = loadData(\"Australia/visual_freq_rat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_1 = runAllDataSet(\"\", data_set_4, data_set_1, data_set_2, data_set_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.03125   , -9.03125   , 62.1875    , 10.        , -9.        ,\n",
       "        62.        , 10.        , -9.        , 62.        ,  0.39404751,\n",
       "         0.17399264,  0.39031237, 10.        , -9.        , 62.        ,\n",
       "        10.        , -9.        , 62.        , 10.        , -9.        ,\n",
       "        62.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [10.1875    , -9.09375   , 62.15625   , 10.        , -9.        ,\n",
       "        62.        , 10.        , -9.        , 62.        ,  0.52663436,\n",
       "         0.2914806 ,  0.36309219, 10.        , -9.        , 62.        ,\n",
       "        10.        , -9.        , 62.        , 10.25      , -9.        ,\n",
       "        62.        ,  0.25      ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_1[:2, :-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "op_driver_1_with_freq = runModelswithFreq(data_set_1)\n",
    "op_driver_2_with_freq = runModelswithFreq(data_set_2)\n",
    "op_driver_3_with_freq = runModelswithFreq(data_set_3)\n",
    "op_driver_4_with_freq = runModelswithFreq(data_set_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "op_driver_1_without_freq = runModelswithoutFreq(data_set_1)\n",
    "op_driver_2_without_freq = runModelswithoutFreq(data_set_2)\n",
    "op_driver_3_without_freq = runModelswithoutFreq(data_set_3)\n",
    "op_driver_4_without_freq = runModelswithoutFreq(data_set_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = loadData(\"3_19/visual_freq_rat_psd.txt\")\n",
    "data_set_2 = loadData(\"4_57/visual_freq_rat_psd.txt\")\n",
    "data_set_3 = loadData(\"5_11/visual_freq_rat_psd.txt\")\n",
    "data_set_4 = loadData(\"Australia/visual_freq_rat_psd.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "op_driver_1_with_freq_psd = runModelswithFreq(data_set_1)\n",
    "op_driver_2_with_freq_psd = runModelswithFreq(data_set_2)\n",
    "op_driver_3_with_freq_psd = runModelswithFreq(data_set_3)\n",
    "op_driver_4_with_freq_psd = runModelswithFreq(data_set_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yaman Sahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "op_driver_1_without_freq_psd = runModelswithoutFreq(data_set_1)\n",
    "op_driver_2_without_freq_psd = runModelswithoutFreq(data_set_2)\n",
    "op_driver_3_without_freq_psd = runModelswithoutFreq(data_set_3)\n",
    "op_driver_4_without_freq_psd = runModelswithoutFreq(data_set_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Descison tree', 100.0, 69.1699604743083], ['Random Forest', 100.0, 77.27272727272727], ['KNN', 79.72858354537745, 75.09881422924902], ['AdaBoost', 73.87616624257845, 73.91304347826086], ['Gaussian NB', 65.13994910941476, 67.58893280632411], ['SVM', 72.17981340118745, 75.29644268774703], ['Gradient Boosting', 91.85750636132316, 74.30830039525692], ['MLP', 77.77777777777779, 72.5296442687747]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def make_plots(op_old, op_with_freq, op_without_freq, op_with_freq_psd, op_without_freq_psd, driver_name):\n",
    "\n",
    "\n",
    "    # Sample data for five datasets\n",
    "    data_sets = [\n",
    "        op_driver_1_old,\n",
    "        op_driver_1_with_freq,\n",
    "        op_driver_1_without_freq,\n",
    "        op_driver_1_with_freq_psd,\n",
    "        op_driver_1_without_freq_psd\n",
    "        ]\n",
    "\n",
    "    # Extracting model names\n",
    "    model_names = [data[0] for data in data_sets[0]]\n",
    "    # Calculate number of rows and columns for subplots\n",
    "    num_rows = 4\n",
    "    num_cols = 2\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 10))  # Reduced height and width\n",
    "\n",
    "    # Flatten axes to simplify indexing\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    bar_width = 0.3  # Set the bar width\n",
    "\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        # Extracting accuracies for the current model\n",
    "        model_data = [data_set[model_names.index(model_name)][1:] for data_set in data_sets]\n",
    "\n",
    "        # Plotting\n",
    "        axes[i].bar(np.arange(len(data_sets)), [x[0] for x in model_data], width=bar_width, label='Train Accuracy')\n",
    "        axes[i].bar(np.arange(len(data_sets)) + bar_width, [x[1] for x in model_data], width=bar_width, label='Test Accuracy')\n",
    "\n",
    "        axes[i].set_title(f'Accuracy Comparison for {model_name}')\n",
    "        axes[i].set_xlabel('Dataset')\n",
    "        axes[i].set_ylabel('Accuracy')\n",
    "        axes[i].set_xticks(np.arange(len(data_sets)) + bar_width / 2)\n",
    "        axes[i].set_xticklabels([f'Data {j+1}' for j in range(len(data_sets))])\n",
    "        # axes[i].legend()\n",
    "\n",
    "    plt.suptitle(f\"Accuracy of Rating for driver {driver_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(op_driver_1_old, op_driver_1_with_freq, op_driver_1_without_freq, op_driver_1_with_freq_psd, op_driver_1_without_freq_psd, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(op_driver_2_old, \n",
    "           op_driver_2_with_freq, \n",
    "           op_driver_2_without_freq, \n",
    "           op_driver_2_with_freq_psd, \n",
    "           op_driver_2_without_freq_psd, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(op_driver_3_old, \n",
    "           op_driver_3_with_freq, \n",
    "           op_driver_3_without_freq, \n",
    "           op_driver_3_with_freq_psd, \n",
    "           op_driver_3_without_freq_psd, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(op_driver_4_old, \n",
    "           op_driver_4_with_freq, \n",
    "           op_driver_4_without_freq, \n",
    "           op_driver_4_with_freq_psd, \n",
    "           op_driver_4_without_freq_psd, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for five datasets\n",
    "data_sets = [\n",
    "    op_driver_1_old,\n",
    "    op_driver_1_with_freq,\n",
    "    op_driver_1_without_freq,\n",
    "    op_driver_1_with_freq_psd,\n",
    "    op_driver_1_without_freq_psd\n",
    "    ]\n",
    "\n",
    "# Extracting model names\n",
    "model_names = [data[0] for data in data_sets[0]]\n",
    "# data_sets = [\"Only Acc\", \"With freq\", \"without\n",
    "\n",
    "# Create separate plots for each model\n",
    "for model_name in model_names:\n",
    "    plt.figure(figsize=(6, 4))  # Smaller figure size\n",
    "\n",
    "    # Extracting accuracies for the current model\n",
    "    model_data = [data_set[model_names.index(model_name)][1:] for data_set in data_sets]\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(np.arange(len(data_sets)), [x[0] for x in model_data], width=0.3)  # Reduced bar width\n",
    "    plt.bar(np.arange(len(data_sets)) + 0.3, [x[1] for x in model_data], width=0.3)  # Adjusted bar position and width\n",
    "\n",
    "    plt.title(f'Accuracy Comparison for {model_name}')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(len(data_sets)) + 0.3 / 2, [f'Data {i+1}' for i in range(len(data_sets))])\n",
    "    # plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Descison tree',\n",
       " 'Random Forest',\n",
       " 'KNN',\n",
       " 'AdaBoost',\n",
       " 'Gaussian NB',\n",
       " 'SVM',\n",
       " 'Gradient Boosting',\n",
       " 'MLP']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
